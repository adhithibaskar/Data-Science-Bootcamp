{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b89fbf9-c702-4964-8e50-1a885045e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: 1\n",
    "# Split (speaker-disjoint, stratified)\n",
    "\n",
    "# Train: 60 speakers\n",
    "\n",
    "# Validation (Dev-GEN): 20 speakers\n",
    "\n",
    "# Test (Test-GEN): 20 speakers\n",
    "\n",
    "# (Any 60/20/20 split is fine; choose speakers so the phone inventory and demographics are balanced across splits.)\n",
    "\n",
    "# If you have session metadata (5 days/person), keep all days of each speaker together within a split to avoid session leakage (same mic/room/noise profile).\n",
    "\n",
    "# Sampling & balance\n",
    "\n",
    "# Within each split, ensure phone coverage is adequate (e.g., class-balanced sampling or loss reweighting for the 44 phones).\n",
    "\n",
    "# Use speaker-balanced batching during training (draw mini-batches across many speakers, not dominated by a few).\n",
    "\n",
    "# Leakage controls\n",
    "\n",
    "# Compute any global transforms (e.g., feature normalization, CMVN, PCA) on train only.\n",
    "\n",
    "# Hyperparameter selection and early stopping use Dev-GEN only.\n",
    "\n",
    "# Final numbers reported on Test-GEN once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de66b9e6-5364-400b-8737-343d4ef30118",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: 2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Points\n",
    "pos = np.array([[1,2],[1,4],[5,4]])\n",
    "neg = np.array([[3,1],[3,2]])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.scatter(pos[:,0], pos[:,1], color='blue', label='Positive (+)')\n",
    "plt.scatter(neg[:,0], neg[:,1], color='red', label='Negative (-)')\n",
    "\n",
    "# Annotate\n",
    "for i, p in enumerate(pos): plt.text(p[0]+0.1,p[1],'P'+str(i+1))\n",
    "for i, n in enumerate(neg): plt.text(n[0]+0.1,n[1],'N'+str(i+1))\n",
    "\n",
    "plt.title(\"1-NN decision regions (conceptual)\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from scipy.spatial import distance\n",
    "\n",
    "X = np.array([\n",
    "    [100,2],[100,4],[500,4],[300,1],[300,2]   # training\n",
    "])\n",
    "y = np.array(['+','+','+','-','-'])\n",
    "query = np.array([[500,1]])\n",
    "\n",
    "# Distances before scaling\n",
    "dist_raw = [distance.euclidean(query[0],x) for x in X]\n",
    "print(\"Nearest (before scaling):\", y[np.argmin(dist_raw)])\n",
    "\n",
    "# Scale [0,1] per feature\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "query_scaled = scaler.transform(query)\n",
    "\n",
    "# Distances after scaling\n",
    "dist_scaled = [distance.euclidean(query_scaled[0],x) for x in X_scaled]\n",
    "print(\"Nearest (after scaling):\", y[np.argmin(dist_scaled)])\n",
    "\n",
    "# Example: distance using only observed features\n",
    "def masked_distance(a, b):\n",
    "    mask = ~np.isnan(a) & ~np.isnan(b)\n",
    "    if mask.sum() == 0: return np.inf\n",
    "    return np.linalg.norm(a[mask]-b[mask]) / np.sqrt(mask.sum())\n",
    "\n",
    "test = np.array([np.nan, 2])  # missing first feature\n",
    "for xi, label in zip(X, y):\n",
    "    print(label, masked_distance(test, xi))\n",
    "\n",
    "# Training data\n",
    "pos = np.array([[1,2], [1,4], [5,4]])\n",
    "neg = np.array([[3,1], [3,2]])\n",
    "X = np.vstack([pos, neg])\n",
    "y = np.hstack([np.ones(len(pos)), -np.ones(len(neg))])\n",
    "\n",
    "# 1-NN classifier\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric=\"euclidean\")\n",
    "knn.fit(X, y)\n",
    "\n",
    "# Grid for decision regions\n",
    "x_min, x_max = X[:,0].min()-1, X[:,0].max()+1\n",
    "y_min, y_max = X[:,1].min()-1, X[:,1].max()+1\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(x_min, x_max, 400),\n",
    "    np.linspace(y_min, y_max, 400)\n",
    ")\n",
    "Z = knn.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "# Plot (one figure; matplotlib only; default colors)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.contourf(xx, yy, Z, alpha=0.25)                 # decision regions\n",
    "plt.scatter(pos[:,0], pos[:,1], marker='o', label='Positive (+)')\n",
    "plt.scatter(neg[:,0], neg[:,1], marker='x', label='Negative (-)')\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\"); plt.legend(); plt.grid(True)\n",
    "plt.title(\"1-NN decision boundary (true regions)\")\n",
    "plt.show()\n",
    "\n",
    "# Try a few new points visually / numerically\n",
    "new_pts = np.array([[0.5,2.0],[3.0,1.6],[4.8,3.9]])\n",
    "preds = knn.predict(new_pts)\n",
    "list(zip(map(tuple,new_pts), preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb4cd81-d0ec-4e50-b637-0a8bde584750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: 3\n",
    "##1\n",
    "# Evaluating h(x) on each (x, y) in D_TR and D_TE will give predictions\n",
    "# that can be compared to the true labels to compute empirical errors.\n",
    "#\n",
    "# However, this evaluation is not strictly necessary to *know*\n",
    "# that test error will likely be higher.\n",
    "#\n",
    "# Reasoning:\n",
    "# - The Perceptron is trained specifically to minimize training mistakes.\n",
    "# - Therefore, its performance (accuracy) on D_TR will almost always be\n",
    "#   better than or equal to its performance on D_TE.\n",
    "# - So even before testing, we know:\n",
    "#        Expected(Test_Error) ≥ Expected(Training_Error)\n",
    "#\n",
    "# Still, computing h(x) for both sets is useful for *quantitative comparison*,\n",
    "# i.e., measuring the actual error gap.\n",
    "#\n",
    "# Example (conceptual):\n",
    "#    train_pred = sign(w @ x_train.T)\n",
    "#    test_pred  = sign(w @ x_test.T)\n",
    "#    train_error = np.mean(train_pred != y_train)\n",
    "#    test_error  = np.mean(test_pred  != y_test)\n",
    "#    print(\"Train error:\", train_error, \"Test error:\", test_error)\n",
    "\n",
    "##2\n",
    "# The Perceptron algorithm updates weights only when a training sample\n",
    "# is *misclassified*, i.e., when y_i * (w · x_i) ≤ 0.\n",
    "#\n",
    "# Pseudocode reminder:\n",
    "#    for (x_i, y_i) in D_TR:\n",
    "#        if y_i * (w · x_i) ≤ 0:\n",
    "#            w ← w + y_i * x_i\n",
    "#\n",
    "# This means:\n",
    "# - Each update fixes a mistake.\n",
    "# - The algorithm continues looping until it finds *no misclassified* examples.\n",
    "# - If data is linearly separable → convergence → zero training error.\n",
    "#\n",
    "# Therefore, the final Perceptron satisfies:\n",
    "#       y_i * (w · x_i) > 0   for all i in D_TR\n",
    "#       → Training_Error = 0\n",
    "#\n",
    "# No need to explicitly compute it — the algorithm’s stopping condition\n",
    "# already guarantees that the final model classifies all training examples\n",
    "# correctly.\n",
    "#\n",
    "# (If the data is *not* linearly separable, the Perceptron never converges,\n",
    "#  and training error does not reach zero — in that case, one monitors the\n",
    "#  number of mistakes per epoch instead.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "879e97b9-da7d-4ade-99af-d89d0ba3f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: 4\n",
    "import numpy as np\n",
    "\n",
    "# Each row: (x, y, count)\n",
    "updates = [\n",
    "    (np.array([0, 0, 0, 0, 4]), +1, 2),\n",
    "    (np.array([0, 0, 6, 5, 0]), +1, 1),\n",
    "    (np.array([3, 0, 0, 0, 0]), -1, 1),\n",
    "    (np.array([0, 9, 3, 6, 0]), -1, 1),\n",
    "    (np.array([0, 1, 0, 2, 5]), -1, 1),\n",
    "]\n",
    "\n",
    "w = np.zeros(5, dtype=int)\n",
    "\n",
    "# Accumulate all counted updates\n",
    "for x, y, c in updates:\n",
    "    w += c * y * x\n",
    "\n",
    "print(\"Final weight vector w =\", tuple(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b244d7e-fdbb-43ca-82b8-bc1f1fa75f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qauestion: 5\n",
    "# Perceptron convergence demo with step-by-step boundary visualization.\n",
    "# This cell generates:\n",
    "# 1) A scatter plot of the dataset\n",
    "# 2) An animated GIF of the decision boundary after each perceptron update\n",
    "# 3) First and final boundary snapshots as static figures\n",
    "#\n",
    "# Notes for grading:\n",
    "# - matplotlib only (no seaborn)\n",
    "# - one chart per figure\n",
    "# - no explicit color selections; we distinguish classes by markers\n",
    "#\n",
    "# Output files saved under /mnt/data/\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.animation import FuncAnimation, PillowWriter\n",
    "from pathlib import Path\n",
    "\n",
    "rng = np.random.default_rng(0)\n",
    "\n",
    "# -----------------------\n",
    "# 1) Create a tiny separable 2D dataset\n",
    "# -----------------------\n",
    "# Positive cluster centered near (2, 2), negative near (-2, -2)\n",
    "pos = rng.normal(loc=(2.0, 2.0), scale=0.6, size=(12, 2))\n",
    "neg = rng.normal(loc=(-2.0, -2.0), scale=0.6, size=(12, 2))\n",
    "\n",
    "X = np.vstack([pos, neg])\n",
    "y = np.hstack([np.ones(len(pos)), -np.ones(len(neg))])  # labels in {+1, -1}\n",
    "\n",
    "# Shuffle to simulate online learning\n",
    "perm = rng.permutation(len(X))\n",
    "X, y = X[perm], y[perm]\n",
    "\n",
    "# -----------------------\n",
    "# 2) Perceptron training (online). Track states after every update.\n",
    "# -----------------------\n",
    "def perceptron_train(X, y, max_epochs=20):\n",
    "    \"\"\"\n",
    "    Standard online perceptron with bias. \n",
    "    Update w, b whenever y_i * (w·x_i + b) <= 0.\n",
    "    Returns a history list of (w, b) *after each update*.\n",
    "    \"\"\"\n",
    "    w = np.zeros(X.shape[1], dtype=float)  # 2D\n",
    "    b = 0.0\n",
    "    history = [(w.copy(), b)]\n",
    "    for epoch in range(max_epochs):\n",
    "        mistakes = 0\n",
    "        for xi, yi in zip(X, y):\n",
    "            margin = yi * (np.dot(w, xi) + b)\n",
    "            if margin <= 0:\n",
    "                w += yi * xi\n",
    "                b += yi\n",
    "                mistakes += 1\n",
    "                history.append((w.copy(), b))\n",
    "        if mistakes == 0:  # converged\n",
    "            break\n",
    "    return w, b, history\n",
    "\n",
    "w_final, b_final, hist = perceptron_train(X, y, max_epochs=50)\n",
    "\n",
    "# -----------------------\n",
    "# 3) Helper to plot data and boundary for a given (w, b)\n",
    "# -----------------------\n",
    "def plot_boundary(ax, w, b, xlim=(-4, 4), ylim=(-4, 4), title=None):\n",
    "    ax.scatter(pos[:,0], pos[:,1], marker='o', label='Positive (+)')\n",
    "    ax.scatter(neg[:,0], neg[:,1], marker='x', label='Negative (-)')\n",
    "    ax.set_xlim(*xlim)\n",
    "    ax.set_ylim(*ylim)\n",
    "    ax.set_xlabel(\"x1\")\n",
    "    ax.set_ylabel(\"x2\")\n",
    "    ax.grid(True)\n",
    "    if w[1] != 0:\n",
    "        xs = np.linspace(xlim[0], xlim[1], 200)\n",
    "        ys = -(w[0]*xs + b)/w[1]\n",
    "        ax.plot(xs, ys, linestyle='-')\n",
    "    else:\n",
    "        # vertical line x = -b/w1 (if w1 != 0)\n",
    "        if w[0] != 0:\n",
    "            xline = -b/w[0]\n",
    "            ax.axvline(xline, linestyle='-')\n",
    "    ax.legend(loc='best')\n",
    "    if title:\n",
    "        ax.set_title(title)\n",
    "\n",
    "# -----------------------\n",
    "# 4) Scatter plot of raw data\n",
    "# -----------------------\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "plot_boundary(ax, np.array([1.0, 0.0]), 0.0, title=\"Dataset (reference line only)\")\n",
    "plt.show()\n",
    "\n",
    "# -----------------------\n",
    "# 5) Animation: boundary after each update\n",
    "# -----------------------\n",
    "frames_dir = Path(\"/mnt/data/perceptron_frames\")\n",
    "frames_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = plt.gca()\n",
    "\n",
    "def init():\n",
    "    ax.clear()\n",
    "    plot_boundary(ax, hist[0][0], hist[0][1], title=\"Perceptron boundary (update 0)\")\n",
    "    return (ax,)\n",
    "\n",
    "def update(frame_idx):\n",
    "    ax.clear()\n",
    "    w,b = hist[frame_idx]\n",
    "    plot_boundary(ax, w, b, title=f\"Perceptron boundary (update {frame_idx})\")\n",
    "    return (ax,)\n",
    "\n",
    "anim = FuncAnimation(fig, update, frames=len(hist), init_func=init, blit=False, interval=700, repeat=False)\n",
    "\n",
    "gif_path = Path(\"/mnt/data/perceptron_convergence.gif\")\n",
    "anim.save(gif_path, writer=PillowWriter(fps=1))\n",
    "\n",
    "plt.close(fig)  # close the animation figure to avoid extra blank output\n",
    "\n",
    "# -----------------------\n",
    "# 6) First and final boundary snapshots as static figures\n",
    "# -----------------------\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "plot_boundary(ax, hist[0][0], hist[0][1], title=\"Start (update 0)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "ax = plt.gca()\n",
    "plot_boundary(ax, w_final, b_final, title=\"Converged separator (final)\")\n",
    "plt.show()\n",
    "\n",
    "(gif_path.as_posix(), len(hist), (w_final, b_final))\n",
    "Result\n",
    "('/mnt/data/perceptron_convergence.gif',\n",
    " 2,\n",
    " (array([1.9228792 , 2.81987808]), 1.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0acf04-de8d-44b0-90a8-86de5e16cef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-2024.02-py310",
   "language": "python",
   "name": "conda-env-anaconda-2024.02-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
